{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "139ac573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cfips  microbusiness_density    active  row_id  county  state  \\\n",
      "0    0.0               0.340296  0.003485     117      82      0   \n",
      "1    0.0               0.326400  0.003342     118      82      0   \n",
      "2    0.0               0.345745  0.003540     119      82      0   \n",
      "3    0.0               0.338661  0.003468     120      82      0   \n",
      "4    0.0               0.338661  0.003468     121      82      0   \n",
      "\n",
      "   first_day_of_month  \n",
      "0                   0  \n",
      "1                   1  \n",
      "2                   2  \n",
      "3                   3  \n",
      "4                   4  \n",
      "(113519, 7)\n",
      "    cfips  row_id  first_day_of_month\n",
      "0  1001.0      24                   0\n",
      "1  1003.0      32                   0\n",
      "2  1005.0      40                   0\n",
      "3  1007.0      48                   0\n",
      "4  1009.0      56                   0\n",
      "(25080, 3)\n",
      "    cfips  microbusiness_density   active  row_id  county  state  \\\n",
      "0  1001.0               3.442677   1463.0       6      82      0   \n",
      "1  1001.0               3.470915   1475.0       7      82      0   \n",
      "2  1003.0               8.257636  14145.0       8      89      0   \n",
      "3  1003.0               8.250630  14133.0       9      89      0   \n",
      "4  1005.0               1.247223    247.0      10     100      0   \n",
      "\n",
      "   first_day_of_month  \n",
      "0                   0  \n",
      "1                   1  \n",
      "2                   0  \n",
      "3                   1  \n",
      "4                   0  \n",
      "(6270, 7)\n",
      "   pct_bb_2017  pct_bb_2018  pct_bb_2019  pct_bb_2020  pct_bb_2021   cfips  \\\n",
      "0         76.6         78.9         80.6         82.7         85.5  1001.0   \n",
      "1         74.5         78.1         81.8         85.1         87.9  1003.0   \n",
      "2         57.2         60.4         60.5         64.6         64.6  1005.0   \n",
      "3         62.0         66.1         69.2         76.1         74.6  1007.0   \n",
      "4         65.8         68.5         73.0         79.6         81.0  1009.0   \n",
      "\n",
      "   pct_college_2017  pct_college_2018  pct_college_2019  pct_college_2020  \\\n",
      "0              14.5              15.9              16.1              16.7   \n",
      "1              20.4              20.7              21.0              20.2   \n",
      "2               7.6               7.8               7.6               7.3   \n",
      "3               8.1               7.6               6.5               7.4   \n",
      "4               8.7               8.1               8.6               8.9   \n",
      "\n",
      "   ...  pct_it_workers_2018  pct_it_workers_2019  pct_it_workers_2020  \\\n",
      "0  ...                  1.1                  0.7                  0.6   \n",
      "1  ...                  1.3                  1.4                  1.0   \n",
      "2  ...                  0.3                  0.8                  1.1   \n",
      "3  ...                  1.4                  1.6                  1.7   \n",
      "4  ...                  1.4                  0.9                  1.1   \n",
      "\n",
      "   pct_it_workers_2021  median_hh_inc_2017  median_hh_inc_2018  \\\n",
      "0                  1.1             55317.0             58786.0   \n",
      "1                  1.3             52562.0             55962.0   \n",
      "2                  0.8             33368.0             34186.0   \n",
      "3                  2.1             43404.0             45340.0   \n",
      "4                  0.9             47412.0             48695.0   \n",
      "\n",
      "   median_hh_inc_2019  median_hh_inc_2020  median_hh_inc_2021    0  \n",
      "0             58731.0             57982.0             62660.0  0.0  \n",
      "1             58320.0             61756.0             64346.0  0.0  \n",
      "2             32525.0             34990.0             36422.0  0.0  \n",
      "3             47542.0             51721.0             54277.0  0.0  \n",
      "4             49358.0             48922.0             52830.0  0.0  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "(3142, 27)\n"
     ]
    }
   ],
   "source": [
    "#PREPROCESS STEP\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "# USING FUNCTION TO HANDLE OUTLIERS\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "#DATASET\n",
    "train_data = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\goodaddy microbusiness dataset\\train.csv\")\n",
    "test_data = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\goodaddy microbusiness dataset\\test.csv\")\n",
    "revealed_test_data = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\goodaddy microbusiness dataset\\revealed_test.csv\")\n",
    "census_data = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\goodaddy microbusiness dataset\\census_starter.csv\")\n",
    "\n",
    "# TRAIN DATASET FEATURE\n",
    "train_df = train_data[['row_id', 'cfips', 'county', 'state', 'first_day_of_month', 'microbusiness_density', 'active']]\n",
    "\n",
    "# ELECT NUMERIC COLUMN\n",
    "train_numeric_columns = train_df.select_dtypes(include='number')\n",
    "\n",
    "# CONVERT NUMERIC COLUMN TO FLOAT\n",
    "train_numeric_columns = train_numeric_columns.astype(float)\n",
    "\n",
    "# ELECT CATEGORICAL COLUMN\n",
    "train_categorical_columns = train_df.select_dtypes(include='object')\n",
    "\n",
    "# LABEL ENCODING TO CATEGORICAL COLUMN\n",
    "label_encoder = LabelEncoder()\n",
    "train_categorical_columns = train_categorical_columns.apply(label_encoder.fit_transform)\n",
    "\n",
    "#CONCATINATE NUMERIC AND LABEL ENCODED CATEGORICAL COLUMN\n",
    "train_df = pd.concat([train_numeric_columns, train_categorical_columns], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TEST DATASET FEATURE\n",
    "test_df = test_data[['row_id', 'cfips', 'first_day_of_month']]\n",
    "\n",
    "\n",
    "\n",
    "# ELECT NUMERIC COLUMN\n",
    "test_numeric_columns = test_df.select_dtypes(include='number')\n",
    "\n",
    "# CONVERT NUMERIC COLUMN TO FLOAT\n",
    "test_numeric_columns = test_numeric_columns.astype(float)\n",
    "\n",
    "# ELECT CATEGORICAL COLUMN\n",
    "test_categorical_columns = test_df.select_dtypes(include='object')\n",
    "\n",
    "# LABEL ENCODING TO CATEGORICAL COLUMN\n",
    "test_categorical_columns = test_categorical_columns.apply(label_encoder.fit_transform)\n",
    "\n",
    "# CONCATENATE NUMRIC AND LABEL ENCODED CATEGORICAL COLUMN\n",
    "test_df = pd.concat([test_numeric_columns, test_categorical_columns], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# REVEALED DATASET FEATURE\n",
    "revealed_df = revealed_test_data[['row_id', 'cfips', 'county', 'state', 'first_day_of_month', 'microbusiness_density', 'active']]\n",
    "\n",
    "# ELECT NUMERIC COLUMN\n",
    "revealed_numeric_columns = revealed_df.select_dtypes(include='number')\n",
    "\n",
    "# CONVERT NUMERIC COLUMN TO FLOAT\n",
    "revealed_numeric_columns = revealed_numeric_columns.astype(float)\n",
    "\n",
    "# ELECT CATEGORICAL COLUMN\n",
    "revealed_categorical_columns = revealed_df.select_dtypes(include='object')\n",
    "\n",
    "# LABEL ENCODING TO CATEGORICAL COLUMN\n",
    "revealed_categorical_columns = revealed_categorical_columns.apply(label_encoder.fit_transform)\n",
    "\n",
    "# CONCATENATE NUMRIC AND LABEL ENCODED CATEGORICAL COLUMN\n",
    "revealed_df = pd.concat([revealed_numeric_columns, revealed_categorical_columns], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# CENSUS_STARTER DATASET FEATURE\n",
    "census_df = census_data[['pct_bb_2017', 'pct_bb_2018', 'pct_bb_2019', 'pct_bb_2020', 'pct_bb_2021', 'cfips',\n",
    "                         'pct_college_2017', 'pct_college_2018', 'pct_college_2019', 'pct_college_2020',\n",
    "                         'pct_college_2021', 'pct_foreign_born_2017', 'pct_foreign_born_2018',\n",
    "                         'pct_foreign_born_2019', 'pct_foreign_born_2020', 'pct_foreign_born_2021',\n",
    "                         'pct_it_workers_2017', 'pct_it_workers_2018', 'pct_it_workers_2019', 'pct_it_workers_2020',\n",
    "                         'pct_it_workers_2021', 'median_hh_inc_2017', 'median_hh_inc_2018', 'median_hh_inc_2019',\n",
    "                         'median_hh_inc_2020', 'median_hh_inc_2021']]\n",
    "\n",
    "# ELECT NUMERIC COLUMN\n",
    "census_numeric_columns = census_df.select_dtypes(include='number')\n",
    "\n",
    "# CONVERT NUMERIC COLUMN TO FLOAT\n",
    "census_numeric_columns = census_numeric_columns.astype(float)\n",
    "\n",
    "# ELECT CATEGORICAL COLUMN\n",
    "census_categorical_columns = census_df.select_dtypes(include='object')\n",
    "\n",
    "# LABEL ENCODING TO CATEGORICAL COLUMN\n",
    "census_categorical_columns = census_categorical_columns.apply(label_encoder.fit_transform)\n",
    "\n",
    "# CONCATENATE NUMRIC AND LABEL ENCODED CATEGORICAL COLUMN\n",
    "census_df = pd.concat([census_numeric_columns, census_categorical_columns], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# FILL MISSING IN TRAIN DATASET\n",
    "train_df.fillna(train_df.mean(), inplace=True)  # Mean for numeric columns\n",
    "train_df.fillna(train_df.mode().iloc[0], inplace=True)  # Mode for categorical columns\n",
    "\n",
    "\n",
    "\n",
    "#FILL MISSING IN TEST DATASET\n",
    "test_df.fillna(test_df.mean(), inplace=True)   # Mean for numeric columns\n",
    "test_df.fillna(test_df.mode().iloc[0], inplace=True)  # Mode for categorical columns\n",
    "\n",
    "\n",
    "# FILL MISSING IN REVEALD DATASET\n",
    "revealed_df.fillna(revealed_df.mean(), inplace=True)  # Mean for numeric columns\n",
    "revealed_df.fillna(revealed_df.mode().iloc[0], inplace=True)  # Mode for categorical columns\n",
    "\n",
    "\n",
    "\n",
    "# FILL MISSING IN CENSUS DATASET\n",
    "\n",
    "census_df.fillna(0, inplace=True)  # Fill missing values with 0 for all columns\n",
    "\n",
    "\n",
    "\n",
    "# HANDLE OUTLIERS\n",
    "train_df = handle_outliers(train_df, 'microbusiness_density')\n",
    "\n",
    "# NORMALIZE AND SCALING \n",
    "scaler = MinMaxScaler()\n",
    "train_df[train_numeric_columns.columns] = scaler.fit_transform(train_df[train_numeric_columns.columns])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(train_df.head())\n",
    "print(train_df.shape)\n",
    "\n",
    "print(test_df.head())\n",
    "print(test_df.shape)\n",
    "\n",
    "print(revealed_df.head())\n",
    "print(revealed_df.shape)\n",
    "\n",
    "print(census_df.head())\n",
    "print(census_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfdade9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808f18b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d54226b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        cfips  microbusiness_density    active  year     month  day  row_id  \\\n",
      "0         0.0               0.340296  0.003485   0.0  0.636364  0.0     117   \n",
      "1         0.0               0.326400  0.003342   0.0  0.727273  0.0     118   \n",
      "2         0.0               0.345745  0.003540   0.0  0.818182  0.0     119   \n",
      "3         0.0               0.338661  0.003468   0.0  0.909091  0.0     120   \n",
      "4         0.0               0.338661  0.003468   0.0  1.000000  0.0     121   \n",
      "...       ...                    ...       ...   ...       ...  ...     ...   \n",
      "122260    1.0               0.204024  0.000282   1.0  0.454545  0.0  117190   \n",
      "122261    1.0               0.204024  0.000282   1.0  0.545455  0.0  117191   \n",
      "122262    1.0               0.202003  0.000279   1.0  0.636364  0.0  117192   \n",
      "122263    1.0               0.202003  0.000279   1.0  0.727273  0.0  117193   \n",
      "122264    1.0               0.202003  0.000279   1.0  0.818182  0.0  117194   \n",
      "\n",
      "        county  state  first_day_of_month  \n",
      "0           82      0                   0  \n",
      "1           82      0                   1  \n",
      "2           82      0                   2  \n",
      "3           82      0                   3  \n",
      "4           82      0                   4  \n",
      "...        ...    ...                 ...  \n",
      "122260    1793     50                  34  \n",
      "122261    1793     50                  35  \n",
      "122262    1793     50                  36  \n",
      "122263    1793     50                  37  \n",
      "122264    1793     50                  38  \n",
      "\n",
      "[113519 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "#PERFORM TIME BASED FEATURE ENGINEERING\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "# USING FUNCTION TO HANDLE OUTLIERS\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "#DATASET\n",
    "train_data = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\goodaddy microbusiness dataset\\train.csv\")\n",
    "test_data = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\goodaddy microbusiness dataset\\test.csv\")\n",
    "revealed_test_data = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\goodaddy microbusiness dataset\\revealed_test.csv\")\n",
    "census_data = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\goodaddy microbusiness dataset\\census_starter.csv\")\n",
    "\n",
    "# TRAIN DATASET FEATURE\n",
    "train_df = train_data[['row_id', 'cfips', 'county', 'state', 'first_day_of_month', 'microbusiness_density', 'active']]\n",
    "\n",
    "#let's START TIME BASED FEATURE ENGINEERING\n",
    "train_df['year'] = pd.to_datetime(train_df['first_day_of_month']).dt.year\n",
    "train_df['month'] = pd.to_datetime(train_df['first_day_of_month']).dt.month\n",
    "train_df['day'] = pd.to_datetime(train_df['first_day_of_month']).dt.day\n",
    "\n",
    "# ELECT NUMERIC COLUMN\n",
    "train_numeric_columns = train_df.select_dtypes(include='number')\n",
    "\n",
    "# CONVERT NUMERIC COLUMN TO FLOAT\n",
    "train_numeric_columns = train_numeric_columns.astype(float)\n",
    "\n",
    "# ELECT CATEGORICAL COLUMN\n",
    "train_categorical_columns = train_df.select_dtypes(include='object')\n",
    "\n",
    "# LABEL ENCODING TO CATEGORICAL COLUMN\n",
    "label_encoder = LabelEncoder()\n",
    "train_categorical_columns = train_categorical_columns.apply(label_encoder.fit_transform)\n",
    "\n",
    "#CONCATINATE NUMERIC AND LABEL ENCODED CATEGORICAL COLUMN\n",
    "train_df = pd.concat([train_numeric_columns, train_categorical_columns], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TEST DATASET FEATURE\n",
    "test_df = test_data[['row_id', 'cfips', 'first_day_of_month']]\n",
    "\n",
    "\n",
    "\n",
    "# STARTING TIMEBASED FEATURE ENGINERRING\n",
    "test_df['year'] = pd.to_datetime(test_df['first_day_of_month']).dt.year\n",
    "test_df['month'] = pd.to_datetime(test_df['first_day_of_month']).dt.month\n",
    "test_df['day'] = pd.to_datetime(test_df['first_day_of_month']).dt.day\n",
    "\n",
    "\n",
    "# ELECT NUMERIC COLUMN\n",
    "test_numeric_columns = test_df.select_dtypes(include='number')\n",
    "\n",
    "# CONVERT NUMERIC COLUMN TO FLOAT\n",
    "test_numeric_columns = test_numeric_columns.astype(float)\n",
    "\n",
    "# ELECT CATEGORICAL COLUMN\n",
    "test_categorical_columns = test_df.select_dtypes(include='object')\n",
    "\n",
    "# LABEL ENCODING TO CATEGORICAL COLUMN\n",
    "test_categorical_columns = test_categorical_columns.apply(label_encoder.fit_transform)\n",
    "\n",
    "# CONCATENATE NUMRIC AND LABEL ENCODED CATEGORICAL COLUMN\n",
    "test_df = pd.concat([test_numeric_columns, test_categorical_columns], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# REVEALED DATASET FEATURE\n",
    "revealed_df = revealed_test_data[['row_id', 'cfips', 'county', 'state', 'first_day_of_month', 'microbusiness_density', 'active']]\n",
    "\n",
    "# STARTING TIMEBASED FEATURE ENGINERRING\n",
    "revealed_df['year'] = pd.to_datetime(revealed_df['first_day_of_month']).dt.year\n",
    "revealed_df['month'] = pd.to_datetime(revealed_df['first_day_of_month']).dt.month\n",
    "revealed_df['day'] = pd.to_datetime(revealed_df['first_day_of_month']).dt.day\n",
    "\n",
    "# ELECT NUMERIC COLUMN\n",
    "revealed_numeric_columns = revealed_df.select_dtypes(include='number')\n",
    "\n",
    "# CONVERT NUMERIC COLUMN TO FLOAT\n",
    "revealed_numeric_columns = revealed_numeric_columns.astype(float)\n",
    "\n",
    "# ELECT CATEGORICAL COLUMN\n",
    "revealed_categorical_columns = revealed_df.select_dtypes(include='object')\n",
    "\n",
    "# LABEL ENCODING TO CATEGORICAL COLUMN\n",
    "revealed_categorical_columns = revealed_categorical_columns.apply(label_encoder.fit_transform)\n",
    "\n",
    "# CONCATENATE NUMRIC AND LABEL ENCODED CATEGORICAL COLUMN\n",
    "revealed_df = pd.concat([revealed_numeric_columns, revealed_categorical_columns], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# CENSUS_STARTER DATASET FEATURE\n",
    "census_df = census_data[['pct_bb_2017', 'pct_bb_2018', 'pct_bb_2019', 'pct_bb_2020', 'pct_bb_2021', 'cfips',\n",
    "                         'pct_college_2017', 'pct_college_2018', 'pct_college_2019', 'pct_college_2020',\n",
    "                         'pct_college_2021', 'pct_foreign_born_2017', 'pct_foreign_born_2018',\n",
    "                         'pct_foreign_born_2019', 'pct_foreign_born_2020', 'pct_foreign_born_2021',\n",
    "                         'pct_it_workers_2017', 'pct_it_workers_2018', 'pct_it_workers_2019', 'pct_it_workers_2020',\n",
    "                         'pct_it_workers_2021', 'median_hh_inc_2017', 'median_hh_inc_2018', 'median_hh_inc_2019',\n",
    "                         'median_hh_inc_2020', 'median_hh_inc_2021']]\n",
    "\n",
    "# ELECT NUMERIC COLUMN\n",
    "census_numeric_columns = census_df.select_dtypes(include='number')\n",
    "\n",
    "# CONVERT NUMERIC COLUMN TO FLOAT\n",
    "census_numeric_columns = census_numeric_columns.astype(float)\n",
    "\n",
    "# ELECT CATEGORICAL COLUMN\n",
    "census_categorical_columns = census_df.select_dtypes(include='object')\n",
    "\n",
    "# LABEL ENCODING TO CATEGORICAL COLUMN\n",
    "census_categorical_columns = census_categorical_columns.apply(label_encoder.fit_transform)\n",
    "\n",
    "# CONCATENATE NUMRIC AND LABEL ENCODED CATEGORICAL COLUMN\n",
    "census_df = pd.concat([census_numeric_columns, census_categorical_columns], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# FILL MISSING IN TRAIN DATASET\n",
    "train_df.fillna(train_df.mean(), inplace=True)  # Mean for numeric columns\n",
    "train_df.fillna(train_df.mode().iloc[0], inplace=True)  # Mode for categorical columns\n",
    "\n",
    "\n",
    "\n",
    "#FILL MISSING IN TEST DATASET\n",
    "test_df.fillna(test_df.mean(), inplace=True)   # Mean for numeric columns\n",
    "test_df.fillna(test_df.mode().iloc[0], inplace=True)  # Mode for categorical columns\n",
    "\n",
    "\n",
    "# FILL MISSING IN REVEALD DATASET\n",
    "revealed_df.fillna(revealed_df.mean(), inplace=True)  # Mean for numeric columns\n",
    "revealed_df.fillna(revealed_df.mode().iloc[0], inplace=True)  # Mode for categorical columns\n",
    "\n",
    "\n",
    "\n",
    "# FILL MISSING IN CENSUS DATASET\n",
    "\n",
    "census_df.fillna(0, inplace=True)  # Fill missing values with 0 for all columns\n",
    "\n",
    "\n",
    "\n",
    "# HANDLE OUTLIERS\n",
    "train_df = handle_outliers(train_df, 'microbusiness_density')\n",
    "\n",
    "# NORMALIZE AND SCALING \n",
    "scaler = MinMaxScaler()\n",
    "train_df[train_numeric_columns.columns] = scaler.fit_transform(train_df[train_numeric_columns.columns])\n",
    "\n",
    "print(train_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ba693f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
